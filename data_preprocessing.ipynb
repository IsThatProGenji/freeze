{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iBc62qggJiDb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hqFuaTnQKKjK"
      },
      "outputs": [],
      "source": [
        "# 1. Load the dataset\n",
        "df = pd.read_csv('i239e_project_train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "E0aNo2x5KL2c"
      },
      "outputs": [],
      "source": [
        "# 2. Preprocessing: Drop non-predictive or high-missingness columns\n",
        "# 'Name', 'Feature#9' (Cabin), and 'Feature#7' (Ticket) are dropped.\n",
        "# 'Feature#1' appears to be a Passenger ID and is also excluded.\n",
        "X = df.drop(columns=['Name', 'Feature#9', 'Feature#7', 'Feature#1', 'Survived'])\n",
        "y = df['Survived']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oZNAtwGvKOML"
      },
      "outputs": [],
      "source": [
        "# 3. Handle Missing Values (Imputation)\n",
        "# Feature#4 (Age) has missing values. We fill them with the median.\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAY53xrpKP3N",
        "outputId": "ce200b5d-12b3-43db-e13e-7829149bfe37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected 5 Features: ['Feature#2', 'Feature#8', 'Feature#4', 'Feature#3', 'Feature#6']\n"
          ]
        }
      ],
      "source": [
        "# 4. Feature Selection using Mutual Information\n",
        "# Top 5 features that share the most information with the 'Survived' label.\n",
        "selector = SelectKBest(score_func=mutual_info_classif, k=5)\n",
        "X_selected = selector.fit_transform(X_imputed, y)\n",
        "\n",
        "# Identify the selected features\n",
        "selected_mask = selector.get_support()\n",
        "selected_features = X.columns[selected_mask].tolist()\n",
        "\n",
        "print(f\"Selected 5 Features: {selected_features}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GqjnaYIOKSmu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved processed_train_features.csv with shape (741, 6)\n",
            "   Feature#2  Feature#8  Feature#4  Feature#3  Feature#6  Survived\n",
            "0   0.831680  -0.242902  -0.877071  -0.743948   0.740426         0\n",
            "1   0.831680  -0.467013   2.565684   1.344179  -0.465411         1\n",
            "2  -0.367299  -0.395034   0.040997  -0.743948  -0.465411         0\n",
            "3   0.831680  -0.197641  -0.112014   1.344179   1.946262         1\n",
            "4  -0.367299  -0.447766  -0.035509   1.344179  -0.465411         1\n"
          ]
        }
      ],
      "source": [
        "# 5. Scaling (Essential for Neural Networks)\n",
        "# We scale the features to a mean of 0 and variance of 1.\n",
        "scaler = StandardScaler()\n",
        "X_final = scaler.fit_transform(X_selected)\n",
        "\n",
        "# Save the transformed training data (features + labels) for the model\n",
        "output_df = pd.DataFrame(X_final, columns=selected_features)\n",
        "output_df['Survived'] = y.values\n",
        "output_df.to_csv('processed_train_features.csv', index=False)\n",
        "print(f\"Saved processed_train_features.csv with shape {output_df.shape}\")\n",
        "print(output_df.head())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
