{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBc62qggJiDb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqFuaTnQKKjK"
      },
      "outputs": [],
      "source": [
        "# 1. Load the dataset (train and test)\n",
        "df_train = pd.read_csv('i239e_project_train.csv')\n",
        "df_test = pd.read_csv('i239e_project_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0aNo2x5KL2c"
      },
      "outputs": [],
      "source": [
        "# 2. Preprocessing: Drop non-predictive or high-missingness columns\n",
        "# 'Name', 'Feature#9' (Cabin), and 'Feature#7' (Ticket) are dropped.\n",
        "# 'Feature#1' appears to be a Passenger ID and is also excluded.\n",
        "X_train = df_train.drop(columns=['Name', 'Feature#9', 'Feature#7', 'Feature#1', 'Survived'])\n",
        "y_train = df_train['Survived']\n",
        "\n",
        "X_test = df_test.drop(columns=['Name', 'Feature#9', 'Feature#7', 'Feature#1'])\n",
        "y_test = df_test['Survived']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZNAtwGvKOML"
      },
      "outputs": [],
      "source": [
        "# 3. Handle Missing Values (Imputation)\n",
        "# Feature#4 (Age) has missing values. We fill them with the median.\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
        "X_test_imputed = pd.DataFrame(imputer.fit_transform(X_test), columns=X_test.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAY53xrpKP3N",
        "outputId": "ce200b5d-12b3-43db-e13e-7829149bfe37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected 5 Features: ['Feature#2', 'Feature#8', 'Feature#4', 'Feature#3', 'Feature#6']\n"
          ]
        }
      ],
      "source": [
        "# 4. Feature Selection using Mutual Information (using Train Data Only)\n",
        "# Top 5 features that share the most information with the 'Survived' label.\n",
        "selector = SelectKBest(score_func=mutual_info_classif, k=5)\n",
        "X_selected = selector.fit_transform(X_train_imputed, y_train)\n",
        "\n",
        "# Identify the selected features\n",
        "selected_mask = selector.get_support()\n",
        "selected_features = X_train_imputed.columns[selected_mask].tolist()\n",
        "\n",
        "print(f\"Selected 5 Features: {selected_features}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqjnaYIOKSmu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved processed_train_features.csv with shape (741, 6)\n",
            "   Feature#2  Feature#8  Feature#4  Feature#3  Feature#6  Survived\n",
            "0   0.831680  -0.242902  -0.877071  -0.743948   0.740426         0\n",
            "1   0.831680  -0.467013   2.565684   1.344179  -0.465411         1\n",
            "2  -0.367299  -0.395034   0.040997  -0.743948  -0.465411         0\n",
            "3   0.831680  -0.197641  -0.112014   1.344179   1.946262         1\n",
            "4  -0.367299  -0.447766  -0.035509   1.344179  -0.465411         1\n"
          ]
        }
      ],
      "source": [
        "# 5. Scaling (Essential for Neural Networks)\n",
        "# We scale the features to a mean of 0 and variance of 1.\n",
        "scaler = StandardScaler()\n",
        "X_final = scaler.fit_transform(X_selected)\n",
        "\n",
        "# Save the transformed training data (features + labels) for the model\n",
        "output_df = pd.DataFrame(X_final, columns=selected_features)\n",
        "output_df['Survived'] = y_train.values\n",
        "output_df.to_csv('processed_train_features.csv', index=False)\n",
        "print(f\"Saved processed_train_features.csv with shape {output_df.shape}\")\n",
        "print(output_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the transformed test data (features + labels) for evaluation, select the same features\n",
        "X_test_selected = selector.transform(X_test_imputed)\n",
        "X_test_final = scaler.transform(X_test_selected)\n",
        "# Identify the selected features\n",
        "selected_mask = selector.get_support()\n",
        "selected_features = X_test_final.columns[selected_mask].tolist()\n",
        "\n",
        "print(f\"Selected 5 Features: {selected_features}\")\n",
        "\n",
        "# output_test_df = pd.DataFrame(X_test_final, columns=selected_features)\n",
        "# output_test_df['Survived'] = y_test.values\n",
        "# output_test_df.to_csv('processed_test_features.csv', index=False)\n",
        "# print(f\"Saved processed_test_features.csv with shape {output_test_df.shape}\")\n",
        "# print(output_test_df.head())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
